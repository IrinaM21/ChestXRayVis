{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PROJ_CSIL_FILE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IrinaM21/ChestXRayVis/blob/master/PROJ_CSIL_FILE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1dIV70K7KzL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "0a78f569-52fb-4dd6-b006-e3c9e4de5775"
      },
      "source": [
        "# temporarily restoring this to run in colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSwAmDKxDdOq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e9628b9-3652-4d77-b407-e094c4471238"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 128\n",
        "num_workers = 0\n",
        "\n",
        "# define transforms:\n",
        "train_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(degrees=10),\n",
        "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "# define datasets:\n",
        "train_data = datasets.ImageFolder(\"/content/gdrive/My Drive/ResearchProject/xrays\", transform=train_transform)\n",
        "val_data = datasets.ImageFolder(\"/content/gdrive/My Drive/ResearchProject/xrays\", transform=test_transform)\n",
        "test_data = datasets.ImageFolder(\"/content/gdrive/My Drive/ResearchProject/xrays\", transform=test_transform)\n",
        "\n",
        "# define dataloaders:\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
        "\n",
        "model = models.resnet18(pretrained=False)\n",
        "\n",
        "# replace the last fc layer with your own linear layer:\n",
        "model.fc = nn.Linear(512, 2)\n",
        "\n",
        "# specify loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "# specify scheduler\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "# number of epochs to train the model\n",
        "n_epochs = 20\n",
        "\n",
        "# lists to keep track of training progress:\n",
        "train_loss_progress = []\n",
        "validation_accuracy_progress = []\n",
        "\n",
        "model.train() # prep model for training\n",
        "\n",
        "n_iterations = int(len(train_data)/batch_size)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # monitor training loss\n",
        "    train_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    for iter, (data, target) in enumerate(train_loader):  \n",
        "        print(\"Epoch:\", epoch, \"Iteration:\", iter, \"out of:\", n_iterations)\n",
        "\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        outputs = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(outputs, target)\n",
        "        \n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        \n",
        "        # update running training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "      \n",
        "    # if you have a learning rate scheduler - perform a its step in here\n",
        "    scheduler.step()\n",
        "    # print training statistics \n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
        "\n",
        "    # Run the test pass:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()  # prep model for validation\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the validation set: %d %%' % (100 * correct / total))\n",
        "\n",
        "PATH = \"/content/gdrive/My Drive/ResearchProject/xrays_model.pt\"\n",
        "# saving entire model:\n",
        "torch.save(model, PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Iteration: 0 out of: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIg8C06j7Mri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "from torchvision import models\n",
        "\n",
        "class FeatureExtractor():\n",
        "    \"\"\" Class for extracting activations and \n",
        "    registering gradients from targeted intermediate layers \"\"\"\n",
        "\n",
        "    def __init__(self, model, target_layers):\n",
        "        self.model = model\n",
        "        self.target_layers = target_layers\n",
        "        self.gradients = []\n",
        "\n",
        "    def save_gradient(self, grad):\n",
        "        self.gradients.append(grad)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        outputs = []\n",
        "        self.gradients = []\n",
        "        for name, module in self.model._modules.items():\n",
        "            x = module(x)\n",
        "            print(name)\n",
        "            print(self.target_layers)\n",
        "            if name in self.target_layers:\n",
        "                #print(name)\n",
        "                x.register_hook(self.save_gradient)\n",
        "                outputs += [x]\n",
        "        return outputs, x\n",
        "\n",
        "\n",
        "class ModelOutputs():\n",
        "    \"\"\" Class for making a forward pass, and getting:\n",
        "    1. The network output.\n",
        "    2. Activations from intermeddiate targetted layers.\n",
        "    3. Gradients from intermeddiate targetted layers. \"\"\"\n",
        "\n",
        "    def __init__(self, model, feature_module, target_layers):\n",
        "        self.model = model\n",
        "        self.feature_module = feature_module\n",
        "        self.feature_extractor = FeatureExtractor(self.feature_module, target_layers)\n",
        "\n",
        "    def get_gradients(self):\n",
        "        return self.feature_extractor.gradients\n",
        "\n",
        "    def __call__(self, x):\n",
        "        target_activations = []\n",
        "        for name, module in self.model._modules.items():\n",
        "            if module == self.feature_module:\n",
        "                target_activations, x = self.feature_extractor(x)\n",
        "            elif \"avgpool\" in name.lower():\n",
        "                x = module(x)\n",
        "                x = x.view(x.size(0),-1)\n",
        "            else:\n",
        "                x = module(x)\n",
        "        \n",
        "        return target_activations, x\n",
        "\n",
        "\n",
        "def preprocess_image(img):\n",
        "    means = [0.485, 0.456, 0.406]\n",
        "    stds = [0.229, 0.224, 0.225]\n",
        "\n",
        "    preprocessed_img = img.copy()[:, :, ::-1]\n",
        "    for i in range(3):\n",
        "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]\n",
        "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]\n",
        "    preprocessed_img = \\\n",
        "        np.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))\n",
        "    preprocessed_img = torch.from_numpy(preprocessed_img)\n",
        "    preprocessed_img.unsqueeze_(0)\n",
        "    input = preprocessed_img.requires_grad_(True)\n",
        "    return input\n",
        "\n",
        "\n",
        "def show_cam_on_image(img, mask):\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
        "    heatmap = np.float32(heatmap) / 255\n",
        "    cam = heatmap + np.float32(img)\n",
        "    cam = cam / np.max(cam)\n",
        "    cv2.imwrite(\"cam.jpg\", np.uint8(255 * cam))\n",
        "\n",
        "\n",
        "class GradCam:\n",
        "    def __init__(self, model, feature_module, target_layer_names):\n",
        "        self.model = model\n",
        "        self.feature_module = feature_module\n",
        "        self.model.eval()\n",
        "        #self.cuda = use_cuda\n",
        "        #if self.cuda:\n",
        "            #self.model = model.cuda()\n",
        "\n",
        "        self.extractor = ModelOutputs(self.model, self.feature_module, target_layer_names)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model(input)\n",
        "\n",
        "    def __call__(self, input, index=None):\n",
        "        #if self.cuda:\n",
        "            #features, output = self.extractor(input.cuda())\n",
        "        #else:\n",
        "        features, output = self.extractor(input)\n",
        "\n",
        "        if index == None:\n",
        "            index = np.argmax(output.cpu().data.numpy())\n",
        "\n",
        "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
        "        one_hot[0][index] = 1\n",
        "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
        "        #if self.cuda:\n",
        "            #one_hot = torch.sum(one_hot.cuda() * output)\n",
        "        #else:\n",
        "        one_hot = torch.sum(one_hot * output)\n",
        "\n",
        "        self.feature_module.zero_grad()\n",
        "        self.model.zero_grad()\n",
        "        one_hot.backward(retain_graph=True)\n",
        "        \n",
        "\n",
        "        # print(self.extractor.get_gradients())\n",
        "        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
        "        \n",
        "\n",
        "        target = features[-1]\n",
        "        target = target.cpu().data.numpy()[0, :]\n",
        "\n",
        "        weights = np.mean(grads_val, axis=(2, 3))[0, :]\n",
        "        cam = np.zeros(target.shape[1:], dtype=np.float32)\n",
        "\n",
        "        for i, w in enumerate(weights):\n",
        "            cam += w * target[i, :, :]\n",
        "\n",
        "        cam = np.maximum(cam, 0)\n",
        "        cam = cv2.resize(cam, input.shape[2:])\n",
        "        cam = cam - np.min(cam)\n",
        "        cam = cam / np.max(cam)\n",
        "        return cam\n",
        "\n",
        "\n",
        "class GuidedBackpropReLU(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(self, input):\n",
        "        positive_mask = (input > 0).type_as(input)\n",
        "        output = torch.addcmul(torch.zeros(input.size()).type_as(input), input, positive_mask)\n",
        "        self.save_for_backward(input, output)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(self, grad_output):\n",
        "        input, output = self.saved_tensors\n",
        "        grad_input = None\n",
        "\n",
        "        positive_mask_1 = (input > 0).type_as(grad_output)\n",
        "        positive_mask_2 = (grad_output > 0).type_as(grad_output)\n",
        "        grad_input = torch.addcmul(torch.zeros(input.size()).type_as(input),\n",
        "                                   torch.addcmul(torch.zeros(input.size()).type_as(input), grad_output,\n",
        "                                                 positive_mask_1), positive_mask_2)\n",
        "\n",
        "        return grad_input\n",
        "\n",
        "\n",
        "class GuidedBackpropReLUModel:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "        #self.cuda = use_cuda\n",
        "        #if self.cuda:\n",
        "            #self.model = model.cuda()\n",
        "\n",
        "        def recursive_relu_apply(module_top):\n",
        "            for idx, module in module_top._modules.items():\n",
        "                recursive_relu_apply(module)\n",
        "                if module.__class__.__name__ == 'ReLU':\n",
        "                    module_top._modules[idx] = GuidedBackpropReLU.apply\n",
        "                \n",
        "        # replace ReLU with GuidedBackpropReLU\n",
        "        recursive_relu_apply(self.model)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model(input)\n",
        "\n",
        "    def __call__(self, input, index=None):\n",
        "        #if self.cuda:\n",
        "            #output = self.forward(input.cuda())\n",
        "        #else:\n",
        "        output = self.forward(input)\n",
        "\n",
        "        if index == None:\n",
        "            index = np.argmax(output.cpu().data.numpy())\n",
        "\n",
        "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
        "        one_hot[0][index] = 1\n",
        "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
        "        #if self.cuda:\n",
        "            #one_hot = torch.sum(one_hot.cuda() * output)\n",
        "        #else:\n",
        "        one_hot = torch.sum(one_hot * output)\n",
        "\n",
        "        # self.model.features.zero_grad()\n",
        "        # self.model.classifier.zero_grad()\n",
        "        one_hot.backward(retain_graph=True)\n",
        "\n",
        "        output = input.grad.cpu().data.numpy()\n",
        "        output = output[0, :, :, :]\n",
        "\n",
        "        return output\n",
        "\n",
        "'''\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--use-cuda', action='store_true', default=False,\n",
        "                        help='Use NVIDIA GPU acceleration')\n",
        "    parser.add_argument('--image-path', type=str, default='./examples/both.png',\n",
        "                        help='Input image path')\n",
        "    args = parser.parse_args()\n",
        "    args.use_cuda = args.use_cuda and torch.cuda.is_available()\n",
        "    if args.use_cuda:\n",
        "        print(\"Using GPU for acceleration\")\n",
        "    else:\n",
        "        print(\"Using CPU for computation\")\n",
        "\n",
        "    return args\n",
        "'''\n",
        "def deprocess_image(img):\n",
        "    \"\"\" see https://github.com/jacobgil/keras-grad-cam/blob/master/grad-cam.py#L65 \"\"\"\n",
        "    img = img - np.mean(img)\n",
        "    img = img / (np.std(img) + 1e-5)\n",
        "    img = img * 0.1\n",
        "    img = img + 0.5\n",
        "    img = np.clip(img, 0, 1)\n",
        "    return np.uint8(img*255)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    \"\"\" python grad_cam.py <path_to_image>\n",
        "    1. Loads an image with opencv.\n",
        "    2. Preprocesses it for VGG19 and converts to a pytorch variable.\n",
        "    3. Makes a forward pass to find the category index with the highest score,\n",
        "    and computes intermediate activations.\n",
        "    Makes the visualization. \"\"\"\n",
        "\n",
        "    # args = get_args()\n",
        "\n",
        "    # Can work with any model, but it assumes that the model has a\n",
        "    # feature method, and a classifier method,\n",
        "    # as in the VGG models in torchvision.\n",
        "    # model = models.resnet50(pretrained=True)\n",
        "    \n",
        "    model = torch.load(PATH)\n",
        "    print(model)\n",
        "    grad_cam = GradCam(model=model, feature_module=model.layer4, target_layer_names=[\"1\"])\n",
        "\n",
        "    img = cv2.imread('/content/gdrive/My Drive/ResearchProject/xrays/NORMAL/NORMAL (1).png', 1)\n",
        "    img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
        "    input = preprocess_image(img)\n",
        "\n",
        "    # If None, returns the map for the highest scoring category.\n",
        "    # Otherwise, targets the requested index.\n",
        "    target_index = 0\n",
        "    mask = grad_cam(input, target_index)\n",
        "\n",
        "    show_cam_on_image(img, mask)\n",
        "\n",
        "    gb_model = GuidedBackpropReLUModel(model=model)\n",
        "    print(model._modules.items())\n",
        "    gb = gb_model(input, index=target_index)\n",
        "    gb = gb.transpose((1, 2, 0))\n",
        "    cam_mask = cv2.merge([mask, mask, mask])\n",
        "    cam_gb = deprocess_image(cam_mask*gb)\n",
        "    gb = deprocess_image(gb)\n",
        "\n",
        "    cv2.imwrite('/content/gdrive/My Drive/ResearchProject/xrays/gb1.jpg', gb)\n",
        "    cv2.imwrite('/content/gdrive/My Drive/ResearchProject/xrays/cam_gb1.jpg', cam_gb)\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhDprqWvFVP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0Y7xqHNEitn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install flashtorch\n",
        "from flashtorch.utils import load_image, apply_transforms, denormalize, format_for_plotting\n",
        "\n",
        "input = apply_transforms(load_image('/content/gdrive/My Drive/ResearchProject/xrays/COVID-19/COVID-19 (31).png'))\n",
        "target_class = 0\n",
        "\n",
        "# this makes our code a little messy but since we need to know gradient values for saliency maps (what we’re starting with) it’s critical\n",
        "backprop = Backprop(model)\n",
        "\n",
        "# less noisy guided visualization\n",
        "guided_gradients = backprop.calculate_gradients(input, target_class, guided=True)\n",
        "guided_gradients = backprop.calculate_gradients(input, target_class, guided=True)\n",
        "max_guided_gradients = backprop.calculate_gradients(input, target_class, take_max=True, guided=True)\n",
        "backprop.visualize(input, target_class)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}